import shlex
import subprocess

import torch
import torchvision.transforms as transforms
from PIL import Image, ImageDraw, ImageFont

import util.util as util


def save_tensor(tensor, path, text="", text_pos="auto", text_color=(255, 255, 255)):
    """Saving a Torch image tensor into an image (with text)"""
    img_nda = util.tensor2im(tensor.data[0])
    img_pil = Image.fromarray(img_nda)

    if text != "":
        if text_pos == "auto":
            # top-right corner
            text_xpos = img_pil.width - 28 * len(text)
            text_ypos = 30
        else:
            text_xpos, text_ypos = text_pos

        draw = ImageDraw.Draw(img_pil)
        font = ImageFont.truetype("/usr/share/fonts/truetype/ubuntu/Ubuntu-B.ttf", 50)
        draw.text((text_xpos, text_ypos), text, text_color, font=font)

    img_pil.save(path)


def save_img(img_pil, path, text="", text_pos="auto", text_color=(255, 255, 255)):
    if text != "":
        if text_pos == "auto":
            # top-right corner
            text_xpos = img_pil.width - 28 * len(text)
            text_ypos = 30
        else:
            text_xpos, text_ypos = text_pos

        draw = ImageDraw.Draw(img_pil)
        font = ImageFont.truetype("/usr/share/fonts/truetype/ubuntu/Ubuntu-B.ttf", 50)
        draw.text((text_xpos, text_ypos), text, text_color, font=font)

    img_pil.save(path)


def im2tensor(img_pil):
    """Go from a PIL image (0..255 RGB) to a (-1..1) tensor"""
    transform_list = [
        # go from 0..255 to 0..1
        transforms.ToTensor(),
        # standard scaling: (t-0.5)/0.5 for all channels
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
    ]
    transform = transforms.Compose(transform_list)
    t = transform(img_pil)
    return t.reshape((1, t.shape[0], t.shape[1], t.shape[2]))


def next_frame_prediction(generator, input_tensor):
    """Just one forward pass through the generator"""
    output_tensor = generator.inference(input_tensor, None, None)
    return output_tensor


def extract_frames_from_video(
    video_path, frame_dir, output_shape=(1280, 736), ffmpeg_verbosity=16
):
    """Extract all frames from a video
      - scale down the frames to match the desired height
      - crop to the desired width
    ex: 1920x1080 --> 1308x736 --> 1280x736
    """
    width, height = output_shape
    command = (
        """ffmpeg -v %d -i %s -q:v 2 -vf "scale=iw*%d/ih:%d, crop=%d:%d" %s/frame-%%06d.jpg -hide_banner"""
        % (ffmpeg_verbosity, video_path, height, height, width, height, frame_dir)
    )
    print(command)
    print("extracting the frames")
    p = subprocess.Popen(shlex.split(command), shell=False)
    p.communicate()


def video_from_frame_directory(
    start_number,
    frame_dir,
    video_path,
    frame_file_glob=r"frame-%05d.jpg",
    framerate=24,
    ffmpeg_verbosity=16,
    crop_to_720p=True,
    reverse=False,
):
    """Build a mp4 video from a directory frames
    note: crop_to_720p crops the top of 1280x736 images to get them to 1280x720
    """
    command = (
        """ffmpeg -start_number %d -v %d -framerate %d -i %s -ss 1 -q:v 2%s %s%s"""
        % (
            start_number,
            ffmpeg_verbosity,
            framerate,
            frame_dir + "/" + frame_file_glob,
            ' -filter:v "crop=1280:720:0:16"' if crop_to_720p else "",
            "-vf reverse " if reverse else "",
            video_path,
        )
    )
    print(command)
    print("building video from frames")
    p = subprocess.Popen(shlex.split(command), shell=False)
    p.communicate()
